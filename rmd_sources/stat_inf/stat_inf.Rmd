---
title: "Confidence Intervals"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(!require("ggplot2")) { install.packages('ggplot2', repos = "http://cran.us.r-project.org"); library("ggplot2") }
```

We can integrate the standard normal to find the following rules of thumb for the distribution density:

- 99% is within about 3 $\sigma$
- 95% is within about 2 $\sigma$
- 68% is within about 1 $\sigma$

```{r fig.height = 3, echo=FALSE}
df1 <- data.frame(x = rnorm(1000))
p1 <- ggplot(df1, aes(x)) + theme(legend.position="none") + xlim(-4, 4)
p1 <- p1 + geom_histogram(aes(y=after_stat(density)), binwidth=0.2, na.rm=TRUE)
p1 <- p1 + stat_function(fun=dnorm, args=list(mean=0, sd=1), colour="red")
p1 <- p1 + stat_function(fun=dnorm, xlim = c(-1, 1), geom = "area")
vline_data = data.frame(x_int = c(-3, -2, -1, 1, 2, 3))
p1 + geom_vline(xintercept=vline_data$x_int, colour="red")
```

Let's see how we can use this to estimate a $95\%$ confidence interval, or an arbitrary $100(1-\alpha)\%$ interval, for the population mean $\mu$ when we do not assume the underlying distribution, but we have many sampled means.

```{r echo=FALSE}
v <- 0.975
```

To build some intuition we can go back to the definition of the quantile: the point $x_v$ for which $CDF(x_v) = P(X \leq x_v) = v$. If our random variable is suitable for the law of large numbers, we can cast this into a normalized value and approximate it with the standard normal quantile, for example with $v = `r v`$:

$$
\begin{align}
P(X \leq x_{`r v`}) &= `r v` \\
P(\frac{X - \mu}{\sigma} \leq \frac{x_{`r v`} - \mu}{\sigma}) &= `r v`.
\end{align}
$$

so the quantile we are looking for is:

$$
\begin{align}
\frac{x_{`r v`} - \mu}{\sigma} &= qnorm(`r v`) = `r qnorm(v)` \\
x_{`r v`} &= \mu + `r qnorm(v)` \sigma.
\end{align}
$$

With probability $`r v`$ a randomly chosen variable will satisfy $x_i \geq \mu + `r qnorm(v)` \sigma$ and by symmetry with probability $`r v`$ a randomly chosen variable will satisfy $x_i \leq \mu - `r qnorm(v)` \sigma$. This looks pretty close to our rule of thumb for $2 \sigma$! Since the density is split evenly among the tails, we have used $v = 1-\alpha/2 = `r v`$ where $\alpha = 0.05$, and say with $95\%$ confidence that the population mean, $\mu$, falls roughly inside the interval:

$$
\bar{X}_n - 2 \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}_n + 2 \frac{\sigma}{\sqrt{n}},
$$

with the sample's [standard error](https://en.wikipedia.org/wiki/Standard_error), $s = \sigma/\sqrt{n}$, replacing the population's unknown standard deviation.

So in general,

$$
P(\mu \in \bar{X}_n \pm z_{(1-\alpha/2)} \frac{\sigma}{\sqrt{n}}) = 100(1-\alpha)\%,
$$

where $z_{(1-\alpha/2)}$ is the corresponding standard normal quantile.

***

**example**

```{r echo=FALSE}
#' n: # number of rexp samples for each mean
#' k: # number of means
generate_means <- function(n, years, prob) {
  #' collect k means, each with n samples, in an array
  sample_means = NULL
  for (i in 1:years) sample_means = c(sample_means, mean(rbinom(n, size=1, prob=prob)))
  means_df <- data.frame(means = sample_means)
  means_df
}
```

```{r echo=FALSE}
#' https://bookdown.org/yihui/rmarkdown-cookbook/font-color.html
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
```

Let's get away from normals for a second and talk about a different sort of process. Every year an inquiry is made into whether the good citizens of Zilcholand would like to run juice through the water lines instead of water. A yes or no is collected from $N = 20000$ people.

```{r fig.height = 3, echo = FALSE}
N <- 1000
years <- 50
p <- 0.4
df3 <- data.frame(vote = factor(rbinom(N, size=1, prob=p)))
df4 <- generate_means(N, years, p)
XBar_n <- mean(df4$means)
low  <- function(quant) { XBar_n - qnorm(quant)*sd(df4$means)/sqrt(length(df4$means)) }
high <- function(quant) { XBar_n + qnorm(quant)*sd(df4$means)/sqrt(length(df4$means)) }
vline_data <- function(quant) { data.frame(x_int = c(low(quant), XBar_n, high(quant))) }
vline_95 <- vline_data(0.95)
vline_99 <- vline_data(0.99)
```

```{r fig.height = 3, echo = FALSE}
p3 <- ggplot(df3, aes(vote))+ geom_bar() + ggtitle("single run")
```

```{r, echo = FALSE}
p4 <- ggplot(df4, aes(means)) + theme(legend.position="none") + ggtitle(paste("means for", as.character(N), " runs"))
p4 <- p4 + geom_histogram(aes(y=after_stat(density)), binwidth=0.006, na.rm=TRUE)
p4 <- p4 + stat_function(fun=dnorm, args=list(mean=XBar_n, sd=sd(df4$means)), colour="red")
p4 <- p4 + xlim(XBar_n + c(-1,1) * 2*sd(df4$means))
p4 <- p4 + geom_vline(xintercept=vline_95$x_int, colour="red")
p4 <- p4 + geom_vline(xintercept=vline_99$x_int, colour="blue")
```

```{r fig.height = 3, echo = FALSE}
library(patchwork)
p3 + p4
```

This is a binomial process which can be modeled with some underlying probabilities $P(\text{yes}) = 1 - P(\text{no})$, but over many referenda the mean vote begins to approximate a normal distribution. If we take the average every time, after `r years` years we get an estimate for the mean response, $\bar{X}_n =`r XBar_n`$, and we can establish with `r colorize("95% confidence", "red")` that the population mean is inside,

$$
`r low(0.95)` \leq \mu \leq `r high(0.95)`
$$

or with `r colorize("99% confidence", "blue")`:

$$
`r low(0.99)` \leq \mu \leq `r high(0.99)`.
$$

In other words we increase confidence by increasing the spread in our estimate. Nonetheless both of these ranges cover the "true" mean of the simulated Zilcholand we were sampling from, where $P = `r p`$ to vote yes.

***

[<- Statistical distributions](./stat_dist.html)

***

[Orbits!](../index.html)
